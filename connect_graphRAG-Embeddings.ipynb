{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook Workflow:**\n",
    "\n",
    "- **Setup Connections:** Connect to Neo4j and OpenAI.\n",
    "- **Fetch and Embed Data:** Retrieve node data from Neo4j and generate embeddings using OpenAI.\n",
    "- **Create FAISS Index:** Create and populate a FAISS index with node embeddings.\n",
    "- **Query and Search:** Perform similarity searches on the FAISS index.\n",
    "- **Format and Save Results:** Format detailed node and relationship information and save results to JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from utils import *\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URI and authentication credentials from environment variables\n",
    "URI = os.getenv(\"NEO4J_URI\")\n",
    "AUTH = (os.getenv(\"NEO4J_USER\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    "\n",
    "# initalize the driver\n",
    "driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "\n",
    "# connect to OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_graph_as_json(driver):\n",
    "    \"\"\"\n",
    "    Fetch all nodes and relationships from Neo4j and return as JSON.\n",
    "    Args:\n",
    "        driver: The Neo4j driver instance.\n",
    "    Returns:\n",
    "        A JSON object containing nodes and relationships.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    MATCH (n)-[r]->(m)\n",
    "    RETURN n, r, m\n",
    "    \"\"\"\n",
    "    graph_data = {\"nodes\": [], \"relationships\": []}\n",
    "    node_ids = set()  # To avoid duplicate nodes\n",
    "\n",
    "    with driver.session() as session:\n",
    "        results = session.run(query)\n",
    "        for record in results:\n",
    "            # Add start node\n",
    "            start_node = record[\"n\"]\n",
    "            if start_node.element_id not in node_ids:\n",
    "                graph_data[\"nodes\"].append({\n",
    "                    \"id\": start_node.element_id,\n",
    "                    \"labels\": list(start_node.labels),\n",
    "                    \"properties\": dict(start_node)\n",
    "                })\n",
    "                node_ids.add(start_node.element_id)\n",
    "\n",
    "            # Add end node\n",
    "            end_node = record[\"m\"]\n",
    "            if end_node.element_id not in node_ids:\n",
    "                graph_data[\"nodes\"].append({\n",
    "                    \"id\": end_node.element_id,\n",
    "                    \"labels\": list(end_node.labels),\n",
    "                    \"properties\": dict(end_node)\n",
    "                })\n",
    "                node_ids.add(end_node.element_id)\n",
    "\n",
    "            # Add relationship\n",
    "            relationship = record[\"r\"]\n",
    "            graph_data[\"relationships\"].append({\n",
    "                \"id\": relationship.element_id,\n",
    "                \"type\": relationship.type,\n",
    "                \"startNode\": relationship.start_node.element_id,\n",
    "                \"endNode\": relationship.end_node.element_id,\n",
    "                \"properties\": dict(relationship)\n",
    "            })\n",
    "\n",
    "    return graph_data\n",
    "\n",
    "def remove_embedding_property(graph_data):\n",
    "    \"\"\"\n",
    "    Remove the 'embedding' property from all nodes in the graph data.\n",
    "    Args:\n",
    "        graph_data: The JSON object containing nodes and relationships.\n",
    "    Returns:\n",
    "        The updated graph data with 'embedding' removed from node properties.\n",
    "    \"\"\"\n",
    "    for node in graph_data[\"nodes\"]:\n",
    "        if \"embedding\" in node[\"properties\"]:\n",
    "            del node[\"properties\"][\"embedding\"]\n",
    "    return graph_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph data saved to graph_data.json without embeddings\n"
     ]
    }
   ],
   "source": [
    "# Fetch the graph data\n",
    "graph_json = fetch_graph_as_json(driver)\n",
    "\n",
    "# Remove 'embedding' property\n",
    "graph_json = remove_embedding_property(graph_json)\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"graph_data.json\", \"w\") as f:\n",
    "    json.dump(graph_json, f, indent=4)\n",
    "\n",
    "print(\"Graph data saved to graph_data.json without embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize KG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get node data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_types():\n",
    "    \"\"\"\n",
    "    Fetch all node labels (types) from the Neo4j database.\n",
    "    Returns:\n",
    "        List of node labels.\n",
    "    \"\"\"\n",
    "    query = \"CALL db.labels() YIELD label RETURN label\"\n",
    "    with driver.session() as session:\n",
    "        results = session.run(query)\n",
    "        return [record[\"label\"] for record in results]\n",
    "\n",
    "node_types = get_node_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_by_type(node_type):\n",
    "    \"\"\"\n",
    "    Fetch all nodes and their properties for a specific node type.\n",
    "    Args:\n",
    "        node_type: The label of the node type to query.\n",
    "    Returns:\n",
    "        List of dictionaries representing nodes and their properties.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    MATCH (n:{node_type})\n",
    "    RETURN properties(n) AS node_properties\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        results = session.run(query)\n",
    "        return [record[\"node_properties\"] for record in results]\n",
    "\n",
    "# Example usage\n",
    "all_nodes = {}\n",
    "for node_type in node_types:\n",
    "    all_nodes[node_type] = get_nodes_by_type(node_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_nodes():\n",
    "    \"\"\"\n",
    "    Fetch all nodes of all types with their properties.\n",
    "    Returns:\n",
    "        List of dictionaries representing all nodes with their type.\n",
    "    \"\"\"\n",
    "    all_nodes = []\n",
    "    for node_type in node_types:\n",
    "        nodes = get_nodes_by_type(node_type)\n",
    "        for node in nodes:\n",
    "            node[\"type\"] = node_type  # Add the node type for context\n",
    "            all_nodes.append(node)\n",
    "    return all_nodes\n",
    "\n",
    "# Example usage\n",
    "graph_data = get_all_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make embeddings for nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_openai_embeddings_for_all(graph_data, batch_size=10):\n",
    "    \"\"\"\n",
    "    Generate embeddings for all nodes using OpenAI embeddings in batches.\n",
    "    Args:\n",
    "        graph_data: List of dictionaries representing graph nodes.\n",
    "        batch_size: Number of nodes to process in each batch.\n",
    "    Returns:\n",
    "        Dictionary mapping node names to their embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    \n",
    "    # Process data in batches\n",
    "    for i in range(0, len(graph_data), batch_size):\n",
    "        batch = graph_data[i:i + batch_size]  # Get the current batch\n",
    "        descriptions = []\n",
    "\n",
    "        # Create descriptions for each node in the batch\n",
    "        for node in batch:\n",
    "            description_parts = [\n",
    "                f\"Type: {node.get('type', 'Unknown')}\",\n",
    "                f\"Name: {node.get('name', 'Unknown')}\",\n",
    "                f\"Label: {node.get('label', '')}\",\n",
    "                f\"Format: {node.get('format', '')}\"\n",
    "            ]\n",
    "            descriptions.append(\" | \".join(part for part in description_parts if part.strip()))\n",
    "\n",
    "        try:\n",
    "            # Generate embeddings for the entire batch\n",
    "            response = client.embeddings.create(\n",
    "                input=descriptions,\n",
    "                model=\"text-embedding-ada-002\"\n",
    "            )\n",
    "            \n",
    "            # Extract embeddings for each description in the batch\n",
    "            for idx, node in enumerate(batch):\n",
    "                embedding = response.data[idx].embedding\n",
    "                embeddings[node[\"name\"]] = embedding\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding batch starting at index {i}: {e}\")\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings made\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "node_embeddings = generate_openai_embeddings_for_all(graph_data)\n",
    "if \"Error\" in node_embeddings:\n",
    "    print(\"Node Embeddings:\", node_embeddings)\n",
    "else:\n",
    "    print(\"Embeddings made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store embeddings\n",
    "with open(\"node_embeddings.json\", \"w\") as f:\n",
    "    json.dump(node_embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Embeddings w faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 555 nodes.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def create_faiss_index(embeddings):\n",
    "    \"\"\"\n",
    "    Create and populate a FAISS index with embeddings.\n",
    "    Args:\n",
    "        embeddings: Dictionary mapping node names to their embeddings.\n",
    "    Returns:\n",
    "        A tuple containing the FAISS index and a list of node names.\n",
    "    \"\"\"\n",
    "    # Extract embeddings and corresponding names\n",
    "    node_names = list(embeddings.keys())\n",
    "    embedding_vectors = np.array(list(embeddings.values()), dtype=\"float32\")\n",
    "\n",
    "    # Create FAISS index (cosine similarity)\n",
    "    dimension = embedding_vectors.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)  # Inner Product (cosine similarity with normalized vectors)\n",
    "\n",
    "    # Normalize vectors for cosine similarity\n",
    "    faiss.normalize_L2(embedding_vectors)\n",
    "\n",
    "    # Add vectors to the index\n",
    "    index.add(embedding_vectors)\n",
    "    return index, node_names\n",
    "\n",
    "# Example usage\n",
    "faiss_index, node_names = create_faiss_index(node_embeddings)\n",
    "print(f\"FAISS index created with {faiss_index.ntotal} nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(faiss_index, \"graph_embeddings.index\")\n",
    "with open(\"node_names.txt\", \"w\") as f:\n",
    "    for name in node_names:\n",
    "        f.write(name + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = faiss.read_index(\"graph_embeddings.index\")\n",
    "with open(\"node_names.txt\", \"r\") as f:\n",
    "    node_names = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_faiss_index(query_text, index, node_names, client):\n",
    "    \"\"\"\n",
    "    Query the FAISS index for similar nodes.\n",
    "    Args:\n",
    "        query_text: The user's query in plain text.\n",
    "        index: The FAISS index containing node embeddings.\n",
    "        node_names: List of node names corresponding to the embeddings in the index.\n",
    "        client: OpenAI client instance to generate query embeddings.\n",
    "    Returns:\n",
    "        List of top matching nodes and their similarity scores.\n",
    "    \"\"\"\n",
    "    # Embed the query using OpenAI\n",
    "    response = client.embeddings.create(\n",
    "        input=query_text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    \n",
    "    # Extract the embedding vector\n",
    "    query_vector = np.array(response.data[0].embedding, dtype=\"float32\").reshape(1, -1)\n",
    "\n",
    "    # Normalize the query vector for cosine similarity\n",
    "    faiss.normalize_L2(query_vector)\n",
    "\n",
    "    # Perform similarity search (retrieve top 5 results)\n",
    "    distances, indices = index.search(query_vector, k=5)\n",
    "\n",
    "    # Map indices back to node names and distances\n",
    "    results = [(node_names[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Results: [('offering_highest_degree', np.float32(0.823972)), ('degree_seeking', np.float32(0.8232179)), ('degree_granting', np.float32(0.79930216)), ('medical_degree', np.float32(0.79743224)), ('other_degree_offered', np.float32(0.79340917))]\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"What data is available about degrees?\"\n",
    "results = query_faiss_index(query, faiss_index, node_names, client)\n",
    "print(\"Top Results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return to sender\n",
    "- aka Format the Results for Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_relationships_from_neo4j(node_name, driver):\n",
    "    \"\"\"\n",
    "    Fetch relationships for a specific node from the Neo4j database.\n",
    "    Args:\n",
    "        node_name: The name of the node.\n",
    "        driver: The Neo4j driver instance.\n",
    "    Returns:\n",
    "        List of dictionaries representing relationships.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    MATCH (n {name: $node_name})-[r]->(m)\n",
    "    RETURN type(r) AS relationship_type, m.name AS target\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        results = session.run(query, node_name=node_name)\n",
    "        return [{\"type\": record[\"relationship_type\"], \"target\": record[\"target\"]} for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_node_details_with_relationships(results, graph_data, driver):\n",
    "    \"\"\"\n",
    "    Retrieve detailed information about matching nodes and their relationships dynamically.\n",
    "    Args:\n",
    "        results: List of tuples containing node names and similarity scores.\n",
    "        graph_data: List of dictionaries representing graph nodes.\n",
    "        driver: The Neo4j driver instance.\n",
    "    Returns:\n",
    "        List of dictionaries with detailed node and relationship information.\n",
    "    \"\"\"\n",
    "    details = []\n",
    "    for node_name, score in results:\n",
    "        node = next((n for n in graph_data if n[\"name\"] == node_name), {})\n",
    "        if node:\n",
    "            node[\"similarity\"] = score\n",
    "            node[\"relationships\"] = fetch_relationships_from_neo4j(node_name, driver)\n",
    "            details.append(node)\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "node_details = fetch_node_details_with_relationships(results, graph_data, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top matching nodes:\n",
      "\n",
      "1. Name: offering_highest_degree\n",
      "   Type: Variable\n",
      "   Label: Highest degree offered\n",
      "   Format: offering_highest_degree\n",
      "   Similarity: 0.8240\n",
      "   Relationships:\n",
      "     - EXISTS_IN directory\n",
      "     - PROVIDED_BY ipeds\n",
      "\n",
      "2. Name: degree_seeking\n",
      "   Type: Variable\n",
      "   Label: Degree/certificate-seeking\n",
      "   Format: degree_seeking\n",
      "   Similarity: 0.8232\n",
      "   Relationships:\n",
      "     - EXISTS_IN fall-enrollment-race\n",
      "     - EXISTS_IN fall-enrollment-age\n",
      "     - EXISTS_IN sfa-grants-and-net-price\n",
      "     - PROVIDED_BY ipeds\n",
      "\n",
      "3. Name: degree_granting\n",
      "   Type: Variable\n",
      "   Label: Degree-granting status\n",
      "   Format: yes_no\n",
      "   Similarity: 0.7993\n",
      "   Relationships:\n",
      "     - EXISTS_IN directory\n",
      "     - PROVIDED_BY ipeds\n",
      "\n",
      "4. Name: medical_degree\n",
      "   Type: Variable\n",
      "   Label: Institution grants a medical degree\n",
      "   Format: yes_no\n",
      "   Similarity: 0.7974\n",
      "   Relationships:\n",
      "     - EXISTS_IN directory\n",
      "     - PROVIDED_BY ipeds\n",
      "\n",
      "5. Name: other_degree_offered\n",
      "   Type: Variable\n",
      "   Label: Other degree offered (yes/no)\n",
      "   Format: yes_no\n",
      "   Similarity: 0.7934\n",
      "   Relationships:\n",
      "     - EXISTS_IN institutional-characteristics\n",
      "     - PROVIDED_BY ipeds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_node_details(node_details):\n",
    "    \"\"\"\n",
    "    Format detailed node and relationship information into a user-friendly string.\n",
    "    Args:\n",
    "        node_details: List of dictionaries containing detailed node and relationship information.\n",
    "    Returns:\n",
    "        A formatted string.\n",
    "    \"\"\"\n",
    "    if not node_details:\n",
    "        return \"No results found.\"\n",
    "\n",
    "    response = \"Here are the top matching nodes:\\n\\n\"\n",
    "    for idx, node in enumerate(node_details, start=1):\n",
    "        # Basic node information\n",
    "        response += (\n",
    "            f\"{idx}. Name: {node['name']}\\n\"\n",
    "            f\"   Type: {node['type']}\\n\"\n",
    "            f\"   Label: {node['label']}\\n\"\n",
    "            f\"   Format: {node['format']}\\n\"\n",
    "            f\"   Similarity: {node['similarity']:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "        # Relationship information\n",
    "        if \"relationships\" in node and node[\"relationships\"]:\n",
    "            response += \"   Relationships:\\n\"\n",
    "            for rel in node[\"relationships\"]:\n",
    "                response += f\"     - {rel['type']} {rel['target']}\\n\"\n",
    "\n",
    "        response += \"\\n\"\n",
    "    return response\n",
    "\n",
    "# Format the results\n",
    "formatted_output = format_node_details(node_details)\n",
    "print(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to call_node_details.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def save_results_to_json(node_details, filename=\"call_node_details.json\"):\n",
    "    \"\"\"\n",
    "    Save node details and relationships to a JSON file.\n",
    "    Args:\n",
    "        node_details: List of dictionaries containing node details and relationships.\n",
    "        filename: Name of the file to save results to.\n",
    "    \"\"\"\n",
    "    # Convert all numpy.float32 to Python float and ensure all data is serializable\n",
    "    def make_serializable(data):\n",
    "        if isinstance(data, np.float32):  # Handle numpy floats\n",
    "            return float(data)\n",
    "        if isinstance(data, list):  # Handle nested lists\n",
    "            return [make_serializable(item) for item in data]\n",
    "        if isinstance(data, dict):  # Handle nested dictionaries\n",
    "            return {key: make_serializable(value) for key, value in data.items()}\n",
    "        return data  # Return native types as-is\n",
    "\n",
    "    serializable_data = [make_serializable(node) for node in node_details]\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(serializable_data, f, indent=4)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "# Example usage\n",
    "save_results_to_json(node_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Add nodes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 9\u001b[0m     net\u001b[38;5;241m.\u001b[39madd_node(node[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[43mnode\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Add edges\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rel \u001b[38;5;129;01min\u001b[39;00m graph_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelationships\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "# see graph\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Create a pyvis network\n",
    "net = Network(height=\"750px\", width=\"100%\", directed=True)\n",
    "\n",
    "# Add nodes\n",
    "for node in graph_json[\"nodes\"]:\n",
    "    net.add_node(node[\"id\"], label=node[\"label\"], title=f\"Type: {node['label']}\")\n",
    "\n",
    "# Add edges\n",
    "for rel in graph_json[\"relationships\"]:\n",
    "    net.add_edge(rel[\"startNode\"], rel[\"endNode\"], title=rel[\"type\"], label=rel[\"type\"])\n",
    "\n",
    "# Show the graph\n",
    "net.show(\"knowledge_graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
